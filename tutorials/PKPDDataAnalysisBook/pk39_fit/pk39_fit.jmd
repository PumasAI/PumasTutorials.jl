---
title: Exercise PK39 - Fitting Two Compartment data - Experimental design issues
date: `j Date(now())`
---

```julia; echo = false
using Dates
```

## Objectives

In this exercise we will learn how to analyze the same dataset with 24 observations,
 14 observations and 9 observations. This will help us to understand if **extra data
 provides any better information**. Finally we will conclude at the number of datapoints
 to be used for analysis until the information is `lost`.

The basic workflow for the estimation process is:

 1. Description of the data
 2. Exploratory analysis of the data
 3. NCA Analysis
 4. Pharmacokinetic modelling
 5. Diagnostic Plots
 6. Validation

Lets load the necessary `libraries` before we get started

```julia
using PumasTutorials
using Random
using CSV
using Pumas
using Plots
using StatsPlots
using Pipe
using StatsBase
using PrettyTables
```

## Description of the data

In this analysis the drug is given as three infusions. Details and doses of the
 infusions are shown below. PK samples are collected at various time points `0.25,
  0.5, 1, 2, 3, 6, 8, 9, 10, 12, 18, 21, 24, 24.5, 25, 26, 28, 30, 32, 34, 36, 42,
  48, 60 hrs`.

```julia
Dosage = DataFrame(- = ["Dose (μg/kg)", "Time Interval"],
 First_Dose = ["26.9", "15 min"], Second_Dose = ["139", "15min - 8hrs"],
 Third_Dose = ["138.95", "8hrs to 24hrs"], Total_Dose=["304.85", "-"])
pretty_table(first(Dosage,10), backend = :html)
```

The following are the units of the dataset:

 * Time (time) = hrs
 * Plasma Concentration (dv) = μg/L
 * Dose (amt) = μg/kg

```julia
pk39_data_df = CSV.read("/Users/Parsshava/Desktop/Julia/PumasTutorials.jl/tutorials/PKPDDataAnalysisBook/pk39_fit/pk_39.csv",
 DataFrame, missingstrings = ["", ".", "NA", "BQL"])
```

Basic summary `statistics` of the data

```julia
stats_pk39_data = describe(pk39_data_df, :min, :max, :mean, :std, :nmissing, cols=[:id,:time,:dv])
```

## Exploratory Plots of the given data

 * Plot of Concentration vs Time

```julia
pk_data_plot = dropmissing(pk39_data_df, :dv)
@df pk_data_plot plot(:time, :dv, group=:id, label=false,
                      xlabel="Time (hr)", ylabel="Concentration (ug/L)",
                      size = (600, 600), guidefontsize = 12,
                      title = "Concentration vs Time")
```

## NCA Analysis

We will perform an `NCA Analysis` to obtain the _AUC_ of the given data. Once we
 have the AUC we will calculate the other parameters for our intial estimates for
 fitting. From the above given data we will select only the columns we require
 for the NCA analysis.

```julia; results="hidden"
pk_data_nca = dropmissing(pk39_data_df, :dv)
select!(pk_data_nca, :id, :time, :dv)
```

Now, map the data variables to the read_nca function that prepares the data for
 NCA analysis. You can even type **?read_nca** in the REPL and get more information
 on the mapping of the data.

```julia
pk39_nca = read_nca(pk_data_nca,
                    id       = :id,
                    time     = :time,
                    conc     = :dv)
```

A full NCAReport is generated, we will then perform summary statistics of the
 required parameters to obtain the **Mean, GeometricMean, and SD**

```julia
pk39_nca_report = NCAReport(pk39_nca, sigdig=3)
```

Perform the Summary `Statistics` for the required NCA Parameters

```julia
## Select the required parameters from the NCA Report
stats_nca_df = select(pk39_nca_report, [:id, :kel, :half_life, :aucinf_obs, :cmax])

## Stack the data for easy computation
stats_nca_stacked = stack(stats_nca_df, [:kel, :half_life, :aucinf_obs, :cmax], [:id])
stats_nca_summary = combine(groupby(stats_nca_stacked,[:variable]),
                            [col => fun for col in [:value]
                            for fun in [mean, geomean, std]])
```

* We have the AUC and Total Dose from which we will calculate the Clearance using
   the formula _Cl = Total Dose / AUC_, i.e **Cl = 0.41 L/kg/hr**
* The Intercompartmental clearance is assumed to be greater than the Clearance
   because of the steep decline in concentration i.e **Q = 1.0 L/kg/hr**
* The Volume of Central Compartment can be calculated as _Doseiv/Cpeak_, i.e
   **Vc = 0.5 L**
* We assume the Volume of the Peripheral Compartment (Vp) to be more than Vc.
   Hence, we will use a value of **Vp=1.2 L** for the initial estimate.

## Pharmacokinetic Modelling

##### Read the dataset into read_pumas()

In the initial analysis we will use the full dataset consiting of **24 observation**

```julia
pk39_data = read_pumas(pk39_data_df,
                        id           = :id,
                        time         = :time,
                        observations = [:dv],
                        amt          = :amt,
                        evid         = :evid,
                        cmt          = :cmt,
                        rate         = :rate)
```

##### Two-Compartment Model

```julia
pk_39           = @model begin
  @param begin
    tvcl        ∈ RealDomain(lower=0)
    tvvc        ∈ RealDomain(lower=0)
    tvvp        ∈ RealDomain(lower=0)
    tvq         ∈ RealDomain(lower=0)
    Ω           ∈ PDiagDomain(4)
    σ²_prop     ∈ RealDomain(lower=0)
  end

  @random begin
    η           ~ MvNormal(Ω)
  end

  @pre begin
    CL          = tvcl * exp(η[1])
    Vc          = tvvc * exp(η[2])
    Vp          = tvvp * exp(η[3])
    Q           = tvq * exp(η[4])
  end

  @dynamics Central1Periph1
    #Central'    =  (Q/Vp)*Peripheral - (Q/Vc)*Central -(CL/Vc)*Central
    #Peripheral' = -(Q/Vp)*Peripheral + (Q/Vc)*Central
  #end

  @derived begin
    cp          = @. Central/Vc
    dv          ~ @. Normal(cp, sqrt(cp^2*σ²_prop))
  end
end
```

We have obtained the initial estimates from `NCA` and few other calculations.

```julia
param_est = (tvcl    = 0.41,
             tvvc    = 0.5,
             tvvp    = 1.2,
             tvq     = 1.0,
             Ω       = Diagonal([0.04,0.04,0.04,0.04]),
             σ²_prop = 0.02)
```

##### NaivePooled Analysis

A quick estimation of the mean parameters can be done by performing a NaivePooled
 Analysis. This will give us a good judgemnt of the parameters obtained from NCA
 Analysis and provide better inital estimates for the fitting.

```julia
pk_39_fit_nv = @time fit(pk_39, pk39_data, param_est,
                    Pumas.NaivePooled(), ensemblealg=EnsembleThreads(),
                    omegas=(:Ω,))

coeftable(pk_39_fit_nv)
```

We will now try to fit a two-compartment model using `FOCEI`

```julia
pk_39_fit = @time fit(pk_39, pk39_data, param_est,
                    Pumas.FOCEI(), ensemblealg=EnsembleThreads())

coeftable(pk_39_fit)
```

We will now obtain the parameter `precision` of the model.

```julia
pk_39_infer = coeftable(infer(pk_39_fit))
```

We will now perform the similar analysis using only **14 observations** from the
 previous dataset. Using only the 14 observations we will filter and then read the
 dataset into _read_pumas()_

```julia
pk39_data_df_14 = filter(x -> x.time in [0,0.25,1,3,8,9,12,18,24,25,28,32,36,48,60], pk39_data_df)

pk39_data_14 = read_pumas(pk39_data_df_14,
                          id           = :id,
                          time         = :time,
                          observations = [:dv],
                          amt          = :amt,
                          evid         = :evid,
                          cmt          = :cmt,
                          rate         = :rate)
```

We will try to fit the 14 observations using `FOCEI`

```julia
pk_39_fit_14 = @time fit(pk_39, pk39_data_14, param_est,
                    Pumas.FOCEI(), ensemblealg=EnsembleThreads())

coeftable(pk_39_fit_14)
```

We will now obtain the parameter `precision` of the model.

```julia
pk_39_infer_14 = coeftable(infer(pk_39_fit_14))
```

We will generate a few goodness of fit plots to check the trends in the model.
 We will first `inspect` the diagnostics of our models.

```julia
pk_39_inspect_14 = inspect(pk_39_fit_14) |> DataFrame
```

We will now perform the similar analysis using only **9 observations** from the
 previous dataset. Using only the 9 observations we will filter and then read the
 dataset into _read_pumas()_

```julia
pk39_data_df_9 = filter(x -> x.time in [0,3,8,12,18,28,32,36,48,60], pk39_data_df)

pk39_data_9 = read_pumas(pk39_data_df_9,
                          id           = :id,
                          time         = :time,
                          observations = [:dv],
                          amt          = :amt,
                          evid         = :evid,
                          cmt          = :cmt,
                          rate         = :rate)
```

```julia
pk_39_fit_9 = @time fit(pk_39, pk39_data_9, param_est,
                    Pumas.FOCEI(), ensemblealg=EnsembleThreads())

coeftable(pk_39_fit_9)
```

We will compare the parameters we have obtained from `24 observation` , `14 observation`
 & `9 observation` dataset. We can see that the 24 obs and 14 obs give similar results
 in the parameters. We have even obatin the precision of the parameters earlier.
 The 9 observation data does not provide the estimates accurately. Thus, we conclude
 that the 14 observation data is enough to provide

```julia
@pipe outerjoin(coeftable(pk_39_fit),
               coeftable(pk_39_fit_14), coeftable(pk_39_fit_9), on = :parameter, makeunique = true) |>
  rename!(_, :estimate => :pk39_24obs, :estimate_1 => :pk39_14obs, :estimate_2 => :pk39_9obs)
```

## Diagnostic Plots

##### Goodness of Fit Plots

```julia
theme(:wong2)

function gof(pktvp_mr_inspect_run2)
  p1 = plot()
  @df pktvp_mr_inspect_run2 scatter!(
      p1,
      :dv_pred, :dv;
      ylabel = "Observed dv (ug/L)",
      xlabel = "Population Predicted (ug/L)",
      label = "",
      legend=false,
  )
  Plots.abline!(p1,  1, 0; primary = false, color=:red, linewidth=4)

  #
  p2 = plot()
  @df pktvp_mr_inspect_run2 scatter!(
    p2,
    :dv_ipred, :dv;
    ylabel = "Observed dv (ug/L)",
    xlabel = "Individual Predicted (ug/L)",
    label = "",
    legend=false,
  )
  Plots.abline!(p2, 1, 0; primary = false, color=:red, linewidth=4)

  p3 = plot()
  @df pktvp_mr_inspect_run2 scatter!(
    p3,
    :time, :dv_wres;
    xlabel = "Time (hr)",
    ylabel = "Conditional Weighted Residuals",
     legend=false
  )
  Plots.abline!(p3, 0, 0; primary = false, color=:red, linewidth=4)

  p4 = plot()
  @df pktvp_mr_inspect_run2 scatter!(
   p4,
   :dv_pred, :dv_wres,
   xlabel = "Population Predicted (ug/L)",
   ylabel = "Conditional Weighted Residuals",
   legend=false
  )
  Plots.abline!(p4, 0, 0; primary = false, color=:red, linewidth=4)

  return plot(p1,p2,p3,p4; size = (1000, 1000))
end

gof(pk_39_inspect_14)
```

##### η-Distribution

```julia
data39_etacov = select(pk_39_inspect_14,["η_1", "η_2", "η_3", "η_4"])
data39_etacov = stack(data39_etacov, ["η_1", "η_2", "η_3", "η_4"])
data39_etacov[!,:variable] .= string.(data39_etacov.variable)
@df data39_etacov groupedviolin(:variable,:value,
                               alpha =0.5, legend=false)
@df data39_etacov groupedboxplot!(:variable,:value,
                               alpha =0.5, label ="")
Plots.abline!(0,0, linewidth=4, color = "black",
              size = (600, 600),
              xlabel = "η's", ylabel = "η_values",
              guidefontsize = 22,
              tickfontsize =14, label ="")
```

## Validation

We will perform a validation of the final model using `Visual Predictive Check`.

```julia
pk_vpc = vpc(pk_39_fit_14, 200; dv=:dv,
              ensemblealg=EnsembleSerial())

plot(pk_vpc,
    size=(800,800), xlabel="Time after dose (hrs)",
    ylabel = "Concentration (ug/L)" ,
    titlefontsize=20,guidefontsize=20,
    markersize=7, markeralpha = 0.5, markercolor =:grey,
    observations = true,
    observed_quantiles = true,
    simquantile_medians = true,
    ci_bands = true,
    legend=true, legendfontsize = 12,
    titlefontcolor = :blue,
    linewidth = 5,
     xtickfont = font(20),
     ytickfont = font(20))
```
